# Soccer Ad Banner Segmentation & Replacement

This project implements semantic segmentation for detecting advertising banners in soccer footage using state-of-the-art Vision Transformer models (DINOv2 and DINOv3). The system can accurately identify TV monitor/banner areas in soccer images and videos, enabling automated advertisement replacement.

## ğŸ¯ Project Overview

The project focuses on **binary semantic segmentation** to distinguish between:
- **Background**: General soccer field, players, and other elements
- **TV Monitor/Banner**: Advertising displays and banners around the field

This enables applications like:
- Automated advertisement replacement in sports broadcasts
- Content analysis for sports marketing
- Real-time banner detection and tracking

## ğŸ“ Project Structure

```
SoccerAdBannerSegmentation-Replacement/
â”œâ”€â”€ README                          # This comprehensive guide
â”œâ”€â”€ Dinov2/                        # DINOv2 implementation (legacy)
â”‚   â”œâ”€â”€ model.py                   # DINOv2 segmentation model
â”‚   â”œâ”€â”€ train.py                   # Training script
â”‚   â”œâ”€â”€ infer_image.py            # Image inference
â”‚   â”œâ”€â”€ config.py                 # Configuration settings
â”‚   â”œâ”€â”€ datasets.py               # Data loading utilities
â”‚   â”œâ”€â”€ engine.py                 # Training/validation loops
â”‚   â”œâ”€â”€ utils.py                  # Helper functions
â”‚   â”œâ”€â”€ requirements.txt          # Dependencies
â”‚   â”œâ”€â”€ README.md                 # DINOv2 specific documentation
â”‚   â””â”€â”€ inference_results_image/   # Sample results
â”œâ”€â”€ Dinov2-few-shot/              # Few-shot learning experiments
â”‚   â””â”€â”€ start.txt                 # Placeholder for future work
â””â”€â”€ Dinov3/                       # DINOv3 implementation (recommended)
    â”œâ”€â”€ model.py                  # DINOv3 segmentation model
    â”œâ”€â”€ train.py                  # Training script with enhanced features
    â”œâ”€â”€ infer_image.py           # Image inference with improved performance
    â”œâ”€â”€ config.py                # Configuration settings
    â”œâ”€â”€ datasets.py              # Data loading with augmentations
    â”œâ”€â”€ engine.py                # Training/validation loops
    â”œâ”€â”€ utils.py                 # Utility functions
    â”œâ”€â”€ requirements.txt         # Updated dependencies
    â”œâ”€â”€ README.md                # DINOv3 specific documentation
    â”œâ”€â”€ input/                   # Input data directory
    â”‚   â””â”€â”€ inference_images/    # Test images
    â””â”€â”€ outputs/                 # Training and inference 
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended for training)
- 8GB+ GPU memory for training

### Installation


 **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

   For CUDA 11.8 (optimal performance):
   ```bash
   pip install torch==2.7.1+cu118 torchvision==0.22.1+cu118 torchaudio==2.7.1+cu118 --index-url https://download.pytorch.org/whl/cu118
   pip install -r requirements.txt --no-deps
   ```

### Dataset Setup

Organize your data in the following structure:

```
input/
â””â”€â”€ dataset/
    â”œâ”€â”€ train_images/          # Training images
    â”œâ”€â”€ train_masks/           # Training binary masks (0=background, 255=banner)
    â”œâ”€â”€ valid_images/          # Validation images
    â””â”€â”€ valid_masks/           # Validation binary masks
```

**Mask Format:**
- Background pixels: `(0, 0, 0)` - Black
- Banner/TV monitor pixels: `(255, 255, 255)` - White

## ğŸ‹ï¸ Training

### DINOv3 Training (Recommended)

```bash
cd Dinov3

# Quick training (small images)
python train.py --lr 0.001 --batch 4 --imgsz 224 224 --epochs 10

# High-quality training (larger images)
python train.py --lr 0.001 --batch 2 --imgsz 384 384 --epochs 15 --scheduler --scheduler-epochs 12

# Production training (full resolution)
python train.py --lr 0.0005 --batch 1 --imgsz 512 512 --epochs 20 --scheduler --scheduler-epochs 15
```

### DINOv2 Training (Legacy)

```bash
cd Dinov2

# Standard training
python train.py --lr 0.001 --batch 20 --imgsz 1914 1074 --epochs 10 --scheduler --scheduler-epochs 8
```

### Training Parameters

- `--lr`: Learning rate (0.0001-0.001)
- `--batch`: Batch size (adjust based on GPU memory)
- `--imgsz`: Input dimensions [width height] (must be multiples of 16 for DINOv3)
- `--epochs`: Number of training epochs
- `--scheduler`: Enable learning rate scheduling
- `--scheduler-epochs`: Epoch to reduce learning rate

## ğŸ”® Inference

### Single Image Inference

```bash
# DINOv3
cd Dinov3
python infer_image.py --imgsz 224 224 --model outputs/best_model_iou.pth --input input/inference_images

# DINOv2
cd Dinov2
python infer_image.py --model outputs/best_model.pth --input path/to/images
```

### Batch Inference

Place multiple images in the input directory and run the inference script. Results will be saved in `outputs/inference_results_image/` with overlay visualizations.

## ğŸ—ï¸ Model Architecture

### DINOv3 (Current)

- **Backbone**: Meta's DINOv3 Vision Transformer
- **Available sizes**: 
  - Small: ViT-S/16 (21M params, 384 hidden dims)
  - Base: ViT-B/16 (86M params, 768 hidden dims)
  - Large: ViT-L/16 (300M params, 1024 hidden dims)
- **Patch size**: 16x16 pixels
- **Features**: Register tokens for enhanced feature quality
- **Input**: Flexible resolution (multiples of 16)

### DINOv2 (Legacy)

- **Backbone**: Facebook's DINOv2 Vision Transformer
- **Patch size**: 14x14 pixels
- **Input**: Fixed or flexible resolution
- **Performance**: Good baseline performance

### Segmentation Head

Both models use a simple yet effective segmentation head:
1. Linear projection from transformer features
2. Bilinear upsampling to original resolution
3. Binary classification (background vs banner)

## ğŸ“Š Performance Monitoring

Training outputs comprehensive metrics:

- **Loss plots**: Training and validation loss curves
- **Accuracy**: Pixel-wise classification accuracy
- **mIoU**: Mean Intersection over Union
- **Model checkpoints**: Best models saved by loss and IoU

All plots and checkpoints are saved in the `outputs/` directory.

## ğŸ”§ Configuration

Modify `config.py` to adjust:

```python
ALL_CLASSES = ['background', 'tvmonitor']  # Class names
LABEL_COLORS_LIST = [(0, 0, 0), (255, 255, 255)]  # Mask colors
VIS_LABEL_MAP = [(0, 0, 0), (0, 255, 0)]  # Visualization colors
```

## ğŸ¨ Results

The system produces:

1. **Segmentation masks**: Binary masks identifying banner regions
2. **Overlay visualizations**: Original image with colored overlay
3. **Performance metrics**: Quantitative evaluation results

Sample results are available in the `inference_results_image/` directories showing successful banner detection in various soccer scenarios.

## ğŸ”„ Migration Guide (DINOv2 â†’ DINOv3)

Key improvements in DINOv3:

- **Better dense features** for segmentation tasks
- **Simplified API** using Hugging Face Transformers
- **Register tokens** for enhanced feature quality
- **Improved scaling** for different input resolutions
- **Better memory efficiency**

To migrate existing models, retrain with DINOv3 using similar hyperparameters but adjusted batch sizes.

## ğŸ› Troubleshooting

### Common Issues

1. **CUDA out of memory**: Reduce batch size or image dimensions
2. **Model download fails**: Check internet connection and Hugging Face access
3. **Poor segmentation quality**: Increase training epochs or use larger model
4. **Input dimension errors**: Ensure dimensions are multiples of 16 (DINOv3)

### Performance Tips

- Use GPU for training (CPU inference is possible but slow)
- Start with smaller models and scale up based on results
- Monitor GPU memory usage and adjust batch size accordingly
- Use mixed precision training for memory efficiency


**Note**: This project is designed for research and educational purposes. For production use, ensure proper testing and validation on your specific data.
